Model coefficients: [-8.32771960e-01 -1.34601200e+00 -2.33427822e-01 -3.24129970e-01
 -5.36958377e-01  2.10840356e-01  5.46337765e-01  2.33900592e-02
  6.86309476e-01 -2.13540424e+00 -5.96252190e-01  1.06970577e+00
  3.17105503e+00  5.23555280e-01  3.84124560e-01  3.49860192e-01
  6.87241077e-01  3.52187104e+00 -3.49601687e-01 -7.23464991e-01
 -5.70342485e-01  5.69940669e-02 -5.76768792e-01  1.28239471e-01
  9.70502622e-03 -3.81935050e-01  9.29304937e-01  3.71329648e-01
  1.45151905e-01 -5.90015519e-01  1.06078965e+01  9.00081011e-01
 -1.94435714e-01  8.14328975e+00 -4.59318844e+00 -1.68774419e-01
  6.83859780e+00  8.16174090e-01  2.60000438e-01 -4.79323701e-01
 -2.64121721e-01  4.41596633e-01  2.71798435e-01 -7.56384912e-02
 -1.46919345e-01  2.15950420e-01 -1.89538288e-02  8.20820295e-03
  4.34907460e-01  1.27867134e-02 -2.54991878e-01 -4.01745674e-01]
Model bias: 0.32276098302288386
Loss on 1 fold
Train loss = 1119.2706130813567
Test loss = 1433.1786812936075

Model coefficients: [-0.23205101 -1.50721963 -0.27748996 -0.39074052 -0.6899385   0.45898972
  0.34046779  0.09025201  0.31205368  0.27252537 -0.42428099  1.15675397
  3.31073688  0.28402108  0.32720427  0.28597109  1.14032253  2.97249426
  0.28457525 -0.64278842 -0.17972003 -0.11719293 -0.38788033 -0.22627872
  0.47851709 -0.39650845  0.33609017  0.4100744   0.25489977 -0.25492712
 11.87425978  0.76969339  0.1371093   9.12385123 -5.10687121 -0.158281
  6.63845439  0.76463735  0.31077885 -0.40390276 -0.44787148  0.40402923
  0.36282159 -0.0982168  -0.1135392   0.18446915  0.03574841 -0.23614127
  0.42258581  0.1491666  -0.31713459 -0.24463869]
Model bias: 0.304034838316457
Loss on 2 fold
Train loss = 1243.7062637383408
Test loss = 1073.1289725686765

Model coefficients: [-1.89724068e-01 -1.51266020e+00  7.16611867e-02 -3.61590380e-01
 -7.01689488e-01  3.40930111e-01  4.83945823e-01 -3.96141131e-02
  4.84741580e-01 -6.55153826e-01 -4.84089371e-01  1.18144076e+00
  2.28965223e+00  3.54467210e-01  4.31203633e-01  2.48779252e-01
  1.10985548e+00  2.11038445e+00  6.54121182e-01 -7.15089869e-01
 -6.52505292e-02  1.44090138e-01 -4.70699136e-01 -1.07799790e-02
  7.85975692e-01 -5.56661284e-01  4.82849980e-01 -5.75240837e-01
  4.16788344e-01 -1.12112058e-01  1.16270006e+01  8.44075613e-01
  3.26888386e-01  8.86597668e+00 -4.95911969e+00 -1.51577168e-01
  6.70708877e+00  6.89045014e-01 -5.51150857e-02 -5.13460362e-01
 -5.80959810e-01  4.12029016e-01  3.97240812e-01  2.16486353e-01
  1.22950650e-01 -1.10538267e-01 -1.19929686e-01 -3.48909370e-02
  6.54900599e-01  3.03676620e-01 -2.71787610e-01 -4.40474748e-01]
Model bias: 0.31816815034967066
Loss on 3 fold
Train loss = 1154.8491299094599
Test loss = 1388.883056156374

Model coefficients: [ 0.64146928 -1.39466223 -0.40155832 -0.36721596 -0.64517622  0.1379666
  0.70330474  0.15009962  0.59800641 -0.68194409 -0.51036049  1.08020866
  1.93875714  0.61367799  0.08134563  0.02602896  1.06151812  1.74239446
  0.42250171 -0.53224401 -0.16065732  0.47929554 -0.10118393  0.28094822
  0.68786487 -0.56214411  0.34491006 -0.32030563  0.41095382  0.46379603
 11.06660726  0.18179353  0.96582971  8.9061019  -5.38656601 -0.23642017
  5.23996509  0.76605443 -0.23813215 -0.58618317 -0.44620524  0.64780088
  0.50444977  0.18498878 -0.10327328 -0.14763169  0.11933516  0.14037051
  0.70050267  0.12211074 -0.42038861 -0.51317907]
Model bias: 0.34317424966485255
Loss on 4 fold
Train loss = 1240.330081444966
Test loss = 1071.4918081829908

Model coefficients: [-0.10179015 -1.48120799 -0.57280703 -0.29701234 -0.48930498  0.51253769
  0.36085827 -0.12639762  0.46629032 -1.68187107 -0.28188435  0.97168518
  3.57540111  0.41412252  0.23886155  0.09122145  1.18000501  2.94453087
  0.19896475 -0.57998551 -0.0393327  -0.07924443 -0.56276635 -0.10949823
  0.86996885 -0.35900664 -0.10428593  0.17996622  0.43542648 -0.36550945
 12.9630508   1.2423163   0.14412983  9.54935332 -4.88552861 -0.22998634
  6.62694649  0.67399312 -0.0484116  -0.49520241 -0.38685465  0.33469184
  0.3904272   0.10484242  0.09764059 -0.09846038 -0.1123352   0.12000348
  0.54389673  0.14188788 -0.30186157 -0.30202758]
Model bias: 0.30686767503635354
Loss on 5 fold
Train loss = 1216.194551998201
Test loss = 1144.7417176735232

Learning rate = 0.0001
Batch size = 2500
Train RMSE on folds 1-5 
33.45550198519455 | 35.26621986743604 | 33.983071225383085 | 35.21832025302976 | 34.87398101734588 | 
Test RMSE on folds 1-5 
37.85734646397721 | 32.75864729454921 | 37.26772137059595 | 32.73364947852578 | 33.834031945269594 | 
Train R2 on folds 1-5 
0.39594601048344563 | 0.42894376488722286 | 0.43288077585379553 | 0.41273883688681323 | 0.4447727214068444 | 
Test R2 on folds 1-5 
0.4426506475348662 | 0.6027241486429236 | 0.33463601245635594 | 0.37920652629682977 | 0.4949433717075548 | 
Train RMSE Mean = 34.55941886967787
Test RMSE Mean = 34.89027931058355
Train R2 Mean = 0.42305642190362436
Test R2 Mean = 0.450832141327706
Train RMSE STD = 0.7188152924210779
Test RMSE STD = 2.22559133816163
Train R2 STD = 0.016995313295192924
Test R2 STD = 0.09350474690173881

-------------------------------------
Model coefficients: [ 1.80903926e-01 -6.83454449e-01 -8.64105328e-01 -2.21961770e-01
  3.60917602e-01  2.31317500e-01  6.68602330e-01 -2.03662789e-01
  1.41362746e+00 -8.56906833e-01 -5.24936983e-01  1.00679372e+00
  2.37740667e+00  2.09614380e-01 -6.13449305e-01  4.74290330e-02
  8.14326418e-01  1.13494580e+00  7.23788167e-01  1.46394057e-01
 -4.55559043e-01  2.35934185e-01 -4.53997624e-01  6.41796431e-01
  3.34905956e-01 -6.49397596e-01  6.06396472e-01 -1.31805878e+00
 -5.41017557e-02  4.50285469e-01  9.65422606e+00  1.03216496e+00
  3.92457818e-01  7.12651386e+00 -4.72620614e+00 -2.29782344e-02
  4.04184331e+00  6.32403023e-01 -4.48004811e-01 -5.30528359e-01
 -5.05362608e-01  6.18028786e-01  4.32740485e-01  4.43449867e-01
 -5.92458253e-02 -5.24804218e-01  1.37736705e-01  7.71050086e-02
  9.63630641e-01  3.79841176e-03 -1.33501346e-01 -5.35983997e-01]
Model bias: 0.36254602422387316
Loss on 1 fold
Train loss = 965.8510397305824
Test loss = 1148.1488335918357

Model coefficients: [-0.2397989  -1.06882981 -0.92671918 -0.2425384  -0.30063478  0.21665877
  0.57258818 -0.12750033  0.69649516 -0.17336099 -0.24330077  1.14645108
  1.78656943  0.48285669 -0.02980869  0.18218064  1.07607279  1.46567202
  0.65858274 -0.25629199 -0.29728124  0.30197254 -0.37603446  0.24663572
  0.38220977 -0.44575392  0.46911242 -1.05040434  0.15409714  0.77345512
 10.67966671  0.69626976  0.98236968  8.16389691 -4.93633106 -0.06536831
  4.23538003  0.50054    -0.36942111 -0.53870863 -0.35381937  0.56888261
  0.51753566  0.15735371 -0.03228191 -0.36873051  0.13841935  0.05609565
  0.83210473  0.04203436 -0.27085816 -0.42531369]
Model bias: 0.35854340025810105
Loss on 2 fold
Train loss = 996.1354148240227
Test loss = 1108.9713925234198

Model coefficients: [ 0.44728632 -1.0135602  -1.00343507 -0.24059156  0.62508413  0.26101058
  0.54531381 -0.29935104  0.94621149 -0.85122329 -0.29801177  0.99091448
  2.52877354  0.2809557  -0.7853542   0.17203899  0.98004108  0.46252458
  1.12816068  0.44284584 -0.25922519  0.23142351 -0.50819334  0.28669046
  0.566201   -0.53698257  0.31996307 -1.66028495  0.2308707   0.41063178
 11.58447361  1.29027808  0.70737697  8.49662776 -4.8769995  -0.15321235
  4.10298234  0.48036773 -0.60004082 -0.52487184 -0.4333538   0.49026404
  0.62137763  0.33930987  0.04961829 -0.63157351  0.2506401   0.10510609
  0.90301904  0.11176588 -0.26012086 -0.48039874]
Model bias: 0.35145532524847684
Loss on 3 fold
Train loss = 996.8650719336829
Test loss = 1107.1818432473826

Model coefficients: [ 1.21869746 -1.09275739 -0.95142872 -0.29012286  0.54380598  0.32012115
  0.68697996 -0.2184015   1.15355191 -0.55641696 -0.46717529  1.00913382
  2.59195886  0.09995869 -0.8608587  -0.04373847  0.96216353  0.38616019
  1.03299619  0.3608482  -0.26935685  0.36713756 -0.37076482  0.40612524
  0.71675972 -0.62947479  0.38665198 -1.7421878   0.16989943  0.1756856
 11.9091887   1.42119992  0.45089111  8.77794071 -4.97370739 -0.07239937
  3.92491358  0.50347562 -0.68805302 -0.79808242 -0.52274928  0.68833899
  0.79536851  0.38092325  0.06782533 -0.60608624  0.10627843  0.32154105
  1.16757982  0.14543232 -0.45652938 -0.68066565]
Model bias: 0.3486314100854373
Loss on 4 fold
Train loss = 1048.369516606504
Test loss = 908.584836639101

Model coefficients: [ 5.71817653e-01 -9.90502368e-01 -9.74937147e-01 -3.74244480e-01
  4.02047818e-01  1.83846446e-01  5.31054863e-01 -3.30014778e-01
  9.48533152e-01 -6.89151028e-01 -3.94070472e-01  1.10020387e+00
  2.50199957e+00  3.50784276e-01 -7.11239695e-01  2.38567587e-01
  1.01810704e+00  1.09636031e+00  9.79030091e-01  2.75319514e-01
 -3.80211587e-01  1.98632312e-01 -5.11635063e-01  2.80129200e-01
  4.14401988e-01 -6.26013695e-01  4.67641773e-01 -1.77923831e+00
  2.31235631e-01  5.51625214e-01  1.16625789e+01  1.07851919e+00
  7.06058547e-01  8.72590293e+00 -4.85177757e+00 -1.80700002e-01
  3.51812080e+00  6.03195845e-01 -5.34038422e-01 -7.00220968e-01
 -5.55569813e-01  7.55709719e-01  6.65707572e-01  3.43399005e-01
 -3.86431727e-02 -4.53262711e-01  9.47450728e-02  2.17021220e-01
  1.12547933e+00  7.80995061e-03 -2.82405141e-01 -7.13951448e-01]
Model bias: 0.3601748749647988
Loss on 5 fold
Train loss = 1062.958687222487
Test loss = 849.10213658216

Learning rate = 0.0001
Batch size = 1000
Train RMSE on folds 1-5 
31.078144084397678 | 31.561612994649415 | 31.573170128032487 | 32.37853481253443 | 32.60304720762289 | 
Test RMSE on folds 1-5 
33.884344963298844 | 33.30122208753637 | 33.27434211592143 | 30.142741027303753 | 29.139357175170492 | 
Train R2 on folds 1-5 
0.3901154281104131 | 0.4394564188040378 | 0.45372356572065986 | 0.4569642915216143 | 0.4446806201507435 | 
Test R2 on folds 1-5 
0.4441062883932386 | 0.37512581350908647 | 0.38056498200026595 | 0.4875207651619277 | 0.5075696006795767 | 
Train RMSE Mean = 31.838901845447385
Test RMSE Mean = 31.94840147384617
Train R2 Mean = 0.4369880648614937
Test R2 Mean = 0.43897748994881913
Train RMSE STD = 0.5659287405877178
Test RMSE STD = 1.9228759145413599
Train R2 STD = 0.024254644399150656
Test R2 STD = 0.05399386903233308

-------------------------------------
Model coefficients: [ 6.10237000e-01 -1.90943539e-01 -1.76830925e+00 -1.75540715e-01
  1.35783418e-01  4.22702557e-01  1.65864437e-01 -1.28662253e-01
  4.19914224e-01  5.16976398e-01 -5.47684924e-01  9.98155954e-01
  2.79290313e+00  9.70916499e-02 -5.64696641e-01  4.46665453e-01
  7.41748454e-01  2.33240901e+00  3.08744680e-01  1.01984522e-02
 -1.78541788e-01 -1.32151743e-01 -3.68719863e-01 -8.42128112e-02
 -2.68470664e-01 -5.94452051e-01  8.84264514e-01 -6.16590036e-01
 -1.85427242e-01  4.10808407e-01  1.16740739e+01  1.77176408e+00
  8.82475105e-01  7.91917441e+00 -4.16874777e+00 -2.62305768e-01
  2.43288238e+00  8.16627469e-01 -3.29237414e-01 -1.73832103e-01
  1.65531589e-01  3.26237501e-01 -7.40110565e-02  2.61009939e-01
 -2.16740834e-01 -8.40486730e-02  1.56518417e-01  3.47038344e-01
  2.53659358e-01 -4.78077169e-01  1.20696770e-01 -3.03602107e-01]
Model bias: 0.2968077505179675
Loss on 1 fold
Train loss = 989.3557726761143
Test loss = 1501.839437931994

Model coefficients: [ 1.08121633 -0.68433422 -1.63780387 -0.19925304 -0.24436807  0.44864226
  0.39735103 -0.10252604  0.47540522  1.1390414  -0.50305774  1.17919474
  2.78343855  0.18852346 -0.38874221  0.25881959  1.27071085  1.6515737
  0.82555042 -0.27712404 -0.14721672  0.06029929 -0.32615056 -0.13836945
  0.31740854 -0.61035117  0.09004923 -1.71298962  0.22363199  0.35815929
 13.27791521  1.67927157  0.81435798  9.39021156 -4.58254142 -0.30964644
  2.20585263  0.69078613 -0.44347874 -0.30716771  0.04150287  0.25360923
  0.38510604  0.21851422 -0.20043663 -0.26891951  0.2273036   0.33841758
  0.43352481 -0.27694073  0.04360796 -0.48921533]
Model bias: 0.31086630148146216
Loss on 2 fold
Train loss = 1199.2954321280622
Test loss = 782.7338784276766

Model coefficients: [ 1.41955608e+00 -5.15255446e-01 -2.16002205e+00 -2.55881534e-01
  6.35546122e-01  5.41822140e-01  2.48060653e-01  3.25760392e-03
  2.03856704e-01 -1.68754675e+00 -5.60054802e-01  1.27111201e+00
  3.77678424e+00 -7.26515171e-02  1.79564181e-01  5.65425893e-01
  1.25782415e+00 -2.64960606e-01  1.51891429e+00  2.24835090e-01
  6.03613246e-02 -1.06222240e-01 -2.52979579e-01 -4.40587893e-01
  2.06209664e-01 -6.46651435e-01  3.81089050e-01 -6.26714662e-01
  5.32310745e-01  2.99476073e-01  1.32354172e+01  2.18593515e+00
  7.92109527e-01  8.98710258e+00 -4.68021942e+00 -3.28629386e-01
  2.20014349e+00  6.54431769e-01 -3.80705660e-01 -8.34002883e-02
 -1.27467027e-01 -4.13664012e-02  3.90029324e-01  2.25257673e-01
 -1.20635365e-02 -3.55899347e-01  1.77457574e-01  2.44512832e-02
  2.98368973e-01 -2.22159602e-02  1.18146696e-01 -2.44505113e-01]
Model bias: 0.3139477155936353
Loss on 3 fold
Train loss = 1035.3798521296003
Test loss = 1443.8809052538109

Model coefficients: [ 1.04780770e+00 -5.98553706e-01 -1.67370810e+00 -1.95673331e-01
  1.88419386e-01  4.30110700e-01  2.39081878e-01  1.17296037e-01
  2.41494617e-01  6.79695018e-01 -4.79923322e-01  1.10237148e+00
  3.25388931e+00  6.24328120e-02 -9.02507108e-01  1.43060516e-01
  1.04388099e+00  1.75014334e+00  8.24714596e-01  9.44521863e-02
 -8.52535878e-03 -1.17588360e-02  4.64457235e-03 -3.03809575e-01
  3.10345757e-01 -5.47278008e-01  4.37338700e-01 -1.57892829e+00
  1.87639657e-01  4.40754932e-01  1.37397029e+01  1.55760430e+00
  1.06974772e+00  9.81724977e+00 -4.71228432e+00 -3.79852197e-01
  2.01333076e+00  8.05326072e-01 -5.40603636e-01 -1.12964559e-01
 -3.88893671e-03  2.14641694e-01  3.04955332e-01  1.95479200e-01
 -1.15836727e-01 -3.00866106e-01  3.77261840e-01  2.21608360e-01
  3.10433820e-01 -1.85282740e-01 -2.63126976e-02 -3.82504801e-01]
Model bias: 0.3105298902205304
Loss on 4 fold
Train loss = 1174.1840901784942
Test loss = 866.0050602612723

Model coefficients: [ 1.30506376e-01 -9.72994396e-01 -2.17074519e-01 -4.39519823e-01
  3.21233823e-01  6.31135391e-01  2.34835589e-01 -3.75457542e-02
  2.09472939e-01  7.50700402e-01 -5.31343177e-01  1.05414143e+00
  3.63304884e+00 -1.21522359e-01 -1.16611006e+00 -1.67648739e-01
  1.16254447e+00  1.95153487e+00  6.82771971e-01  9.36557572e-02
  9.93463510e-02 -1.20821111e-01 -2.39393440e-01 -4.70026313e-01
  8.30502629e-01 -6.14996398e-01 -2.77728875e-03 -1.91269137e+00
  7.47902706e-02 -1.06221004e-01  1.35610978e+01  1.47053319e+00
  5.68146845e-01  9.84170583e+00 -4.57642973e+00 -2.61815272e-01
  4.17885581e+00  7.27470721e-01 -4.49022921e-01 -1.91099913e-01
  3.63039828e-02  2.59008576e-01  2.24515724e-01  1.03001597e-01
 -3.24014408e-02 -2.07005478e-01  1.53252459e-01  2.89658148e-01
  4.19641804e-01 -2.93977729e-01 -5.36651674e-02 -2.98432379e-01]
Model bias: 0.3089599273584525
Loss on 5 fold
Train loss = 1107.1844754323945
Test loss = 1439.7706244705846

Learning rate = 0.0001
Batch size = 500
Train RMSE on folds 1-5 
31.454026334892554 | 34.63084509693724 | 32.17731890834909 | 34.26636966733555 | 33.27438166867109 | 
Test RMSE on folds 1-5 
38.75357322792305 | 27.977381550596842 | 37.99843293155404 | 29.427963916337678 | 37.94430951368841 | 
Train R2 on folds 1-5 
0.3991253286986059 | 0.42377619468089484 | 0.4508313211615438 | 0.45295782340263485 | 0.47515476030113113 | 
Test R2 on folds 1-5 
0.4206615170375741 | 0.6336004880331771 | 0.26541160859266666 | 0.5655249983938822 | 0.7139752057429948 | 
Train RMSE Mean = 33.16058833523711
Test RMSE Mean = 34.42033222802
Train R2 Mean = 0.44036908564896204
Test R2 Mean = 0.5198347635600589
Train RMSE STD = 1.2063605472120753
Test RMSE STD = 4.699650048864826
Train R2 STD = 0.026284403623503615
Test R2 STD = 0.15955389279138285

-------------------------------------
Model coefficients: [-2.36530710e-01 -7.49555671e-01 -5.01727887e-01 -6.52703667e-02
 -8.35143963e-02  4.56250222e-01  6.62479131e-01 -4.33070076e-01
  1.18671142e+00 -6.76374501e-01 -6.88489051e-01  9.52194581e-01
  3.01822177e+00 -1.41813150e-01  3.46806336e-02 -1.02703662e-01
  9.37925880e-01  2.00269266e+00  4.07108390e-01 -5.59588249e-01
 -2.66760247e-01  3.09821812e-01 -6.86147506e-01  5.45019635e-01
  3.30940351e-01 -7.26230513e-01  2.73713361e-01  1.10082279e+00
 -1.39695510e-01  2.10684352e-01  1.03462631e+01  1.27305532e+00
  2.44362363e-01  7.43083435e+00 -4.24418207e+00  6.53626778e-03
  4.73536150e+00  6.98182377e-01 -1.09526492e-01 -2.47124334e-01
 -9.08498951e-02  3.01408979e-01 -3.49933960e-02  2.76486833e-01
 -1.18678568e-01 -5.07399358e-02 -8.58049044e-02  2.23973469e-02
  3.86396075e-01 -2.98430132e-01  2.27356754e-01 -1.98146727e-01]
Model bias: 0.2959689212952038
Loss on 1 fold
Train loss = 948.1695925010367
Test loss = 1513.6514960923716

Model coefficients: [ 1.32229827e-01 -9.98826788e-01 -5.62119189e-01 -1.22643054e-01
  2.22948598e-01  4.53546911e-01  4.95671858e-01 -1.67740617e-01
  8.22403121e-01 -3.97892694e-01 -6.45435638e-01  9.80824116e-01
  2.61098559e+00  8.31893458e-02 -7.20541515e-02 -1.67934017e-02
  9.79459530e-01  1.09525970e+00  8.40364072e-01 -2.15851752e-01
 -1.26932826e-01  2.22715968e-01 -3.24005108e-01  2.75499672e-01
  3.47815046e-01 -7.87704312e-01  2.99702992e-01  3.79236769e-01
  2.66595380e-01  8.97362164e-01  1.13322944e+01  6.14512250e-01
  1.20122251e+00  8.74958129e+00 -4.92273808e+00 -2.10960341e-01
  4.94372342e+00  5.19754617e-01 -2.89516049e-01 -3.37648462e-01
 -2.66477793e-01  2.83023970e-01  3.36302216e-01  2.10417689e-01
  3.27978089e-02 -6.58565805e-02  1.08635604e-02 -1.37722666e-01
  5.76060869e-01 -1.39980455e-01  5.26097752e-02 -2.95958330e-01]
Model bias: 0.31231857816362185
Loss on 2 fold
Train loss = 1134.3413527202238
Test loss = 866.979781391891

Model coefficients: [ 4.12293981e-01 -9.34951438e-01 -7.15383233e-01 -1.16690505e-01
  3.28801781e-01  7.45298318e-01  6.59958083e-01 -5.14174923e-01
  1.09220654e+00 -9.67495613e-01 -7.67094322e-01  9.97580679e-01
  3.15981201e+00 -1.47815473e-01 -1.28348571e-01 -6.72275512e-02
  9.47482120e-01  9.32066173e-01  9.36184759e-01 -2.95316906e-01
  1.12741906e-01  3.43647935e-01 -6.79111508e-01  3.44170969e-01
  6.74791221e-01 -9.86123536e-01  4.38019001e-01  1.19310185e-01
  2.19234060e-01  4.61953964e-01  1.16997120e+01  1.37040527e+00
  6.05560773e-01  8.51793771e+00 -4.75073513e+00 -1.74244373e-01
  3.63330319e+00  4.83737136e-01 -5.40289309e-01 -3.50990383e-01
 -2.58032790e-01  5.19069959e-01  4.02313578e-01  2.32244481e-01
 -7.13625953e-02 -2.54313999e-01  2.61797704e-01 -1.07124643e-02
  7.50704255e-01 -2.03519642e-01 -1.49667137e-01 -3.80062098e-01]
Model bias: 0.32247713664006866
Loss on 3 fold
Train loss = 1028.0407255513055
Test loss = 1297.5293793281426

Model coefficients: [ 0.64389503 -1.1411739  -0.66477398 -0.06598513  0.30626302  0.53856262
  0.43871918 -0.28169108  0.48208594 -0.29442503 -0.53600292  1.04061105
  2.76358339 -0.05565808 -0.07958218  0.34359157  1.02417353  0.66444483
  1.00853093 -0.1793708   0.02802627  0.19263969 -0.43673175 -0.02444588
  0.44850475 -0.74152087  0.32865715 -0.78082224  0.18632785  0.43696424
 12.34868321  1.23664132  0.91248959  9.08852056 -4.97312822 -0.06399901
  4.17057391  0.52973436 -0.47538358 -0.37338482 -0.33274054  0.45156139
  0.39935376  0.30911518 -0.03509326 -0.23438232  0.15579581  0.01623597
  0.65331135 -0.10800805 -0.07086821 -0.40659717]
Model bias: 0.32609373955619797
Loss on 4 fold
Train loss = 1102.8677686306423
Test loss = 1007.9135684314537

Model coefficients: [ 0.02158045 -1.21156009 -0.39281359 -0.2073995  -0.25379796  0.16542176
  0.64117417 -0.32921797  0.67321541  0.07984872 -0.50081132  1.0127237
  2.48217068  0.13541597 -0.13764256  0.11296506  1.12602913  0.86736738
  0.9042737  -0.45735217 -0.31062842  0.42777018 -0.48176261  0.18478396
  0.15193457 -0.60934655 -0.03741567 -0.42987257  0.39858948  0.92451973
 11.82060443  0.5480015   1.25489935  9.27436578 -4.99187496 -0.09099414
  4.44496533  0.52988391 -0.41766693 -0.5271765  -0.27129295  0.56954533
  0.42601864  0.22884751 -0.06848609 -0.17485882  0.12805907  0.03439694
  0.72751649 -0.1415332  -0.18058138 -0.38099798]
Model bias: 0.340252218241648
Loss on 5 fold
Train loss = 1166.435063778719
Test loss = 759.3040839084723

Learning rate = 0.0001
Batch size = 2000
Train RMSE on folds 1-5 
30.792362567705595 | 33.6799844524938 | 32.06307417499616 | 33.209453001075495 | 34.15311206579452 | 
Test RMSE on folds 1-5 
38.905674343113134 | 29.444520396703545 | 36.02123511663839 | 31.747654534334558 | 27.55547284857352 | 
Train R2 on folds 1-5 
0.3904940584489598 | 0.4286223323531682 | 0.4375987135097209 | 0.4494267874194865 | 0.43735991601239266 | 
Test R2 on folds 1-5 
0.45084195214452494 | 0.4856380653801623 | 0.2941891212278279 | 0.4145022095499684 | 0.5583713282621644 | 
Train RMSE Mean = 32.77959725241311
Test RMSE Mean = 32.734911447872626
Train R2 Mean = 0.4287003615487455
Test R2 Mean = 0.4407085353129296
Train RMSE STD = 1.211983748231059
Test RMSE STD = 4.183447660770213
Train R2 STD = 0.020216235879182087
Test R2 STD = 0.08731619765793247

-------------------------------------
Model coefficients: [-4.92964339e-01 -7.54564616e-01 -4.52199474e-01 -7.44764812e-02
  3.25568140e-01  1.63913538e-01  3.54861319e-01  4.16760158e-01
  2.62868577e-01  1.17686956e+00 -3.45535316e-01  6.13624988e-01
  1.88700909e+00  5.90038255e-02 -2.93697775e-01  3.97869357e-01
  7.69284879e-01  1.46688836e+00  4.90256241e-01  1.59984704e-01
 -2.58103631e-02  1.92654358e-01  3.12314765e-01  8.95622394e-02
 -1.88387927e-01 -4.61368253e-01 -2.08980492e-01 -5.74812417e-02
 -1.21497618e-02  1.55653267e+00  9.30531492e+00 -4.48255603e-01
  1.98788393e+00  7.89530785e+00 -4.67340887e+00 -4.48890303e-02
  2.43309776e+00  9.84960977e-01  2.78200854e-02  2.63125798e-03
 -1.52294795e-01  3.56524894e-01  9.09642781e-02 -1.61518785e-02
 -3.25418492e-01  1.49238309e-01  2.85432617e-01  6.55357908e-02
  1.22035385e-02 -7.79795865e-02 -1.46801492e-02 -4.01590849e-01]
Model bias: 0.3273724525536539
Loss on 1 fold
Train loss = 1029.0061073381528
Test loss = 1678.1502918216956

Model coefficients: [-2.49273782e-01 -1.13732132e+00 -3.12522259e-01 -2.17637376e-01
  2.08436804e-01  1.92910741e-01  4.14062275e-01  5.94774416e-01
  4.23068150e-01 -1.26699097e+00 -5.07255416e-01  6.77051096e-01
  2.54184509e+00  2.57689582e-01 -2.01079408e-01  1.76233254e-01
  1.02200812e+00  2.04589462e+00  5.82580246e-01  8.43345173e-02
 -8.38843995e-02  1.85730005e-01  4.69773263e-01  1.40127149e-01
  1.76950247e-01 -7.10923717e-01 -5.47122630e-01  4.26693086e-01
  2.29256401e-01  1.58082569e+00  1.14594383e+01 -4.73838367e-01
  2.04662363e+00  9.77061681e+00 -4.94542285e+00  1.86230590e-03
  3.05810300e+00  7.72524375e-01 -1.42601527e-01 -7.52203409e-02
 -1.16061101e-01  2.32351846e-01  3.07443658e-01  1.15286491e-01
 -3.51235218e-01  5.37120609e-02  2.12000960e-01  1.03625199e-01
  7.53139355e-02 -4.22553105e-02  3.88311400e-02 -4.27097996e-01]
Model bias: 0.3188268516212144
Loss on 2 fold
Train loss = 1209.419293372876
Test loss = 865.3343296683246

Model coefficients: [ 0.13516107 -1.07888368 -0.2618231  -0.16250808 -0.05866626  0.13008385
  0.4590375   0.40352747  0.26282737 -0.64455561 -0.42759985  0.77513745
  1.74117636  0.26652059  0.01433156  0.32452061  0.96840738  0.96677297
  0.76048999 -0.0795781  -0.06371789  0.34726911  0.31922174  0.08601559
 -0.0490609  -0.57426301 -0.19570961  0.10608872  0.38666278  2.04226285
 10.50280524 -0.54013313  2.46071473  8.93356864 -5.07714172 -0.19097411
  2.42599689  0.78284487 -0.08083159 -0.04468983 -0.22587072  0.37265613
  0.24518521 -0.05393588 -0.23546583  0.07585688  0.23610331 -0.04871944
  0.22817903  0.01098424 -0.11189072 -0.38079774]
Model bias: 0.3543027094708627
Loss on 3 fold
Train loss = 1144.6927454386387
Test loss = 1158.3835048463443

Model coefficients: [ 2.79975959e-01 -1.01808900e+00 -1.60852475e-01 -2.03988308e-01
 -1.34069892e-01  1.42266040e-01  4.20524663e-01  2.56531107e-01
  3.83484486e-01 -1.08022608e+00 -4.75012032e-01  7.98602470e-01
  2.33275145e+00  3.02550267e-01 -9.13716846e-03  1.16290836e-01
  1.07891469e+00  1.26877815e+00  7.35424752e-01 -1.60870385e-01
 -1.53081207e-02  2.95748025e-01  1.48708110e-01  2.12368757e-01
  1.68874619e-01 -6.21186168e-01 -3.76625112e-01  6.27620576e-01
  4.20103293e-01  1.75676073e+00  1.12594397e+01 -2.24968197e-01
  2.22372118e+00  9.37106913e+00 -5.26800973e+00 -3.93755298e-02
  2.33533446e+00  8.20064074e-01 -1.00406050e-01 -2.97214200e-01
 -1.78205729e-01  3.75323207e-01  2.45454224e-01  1.91715753e-01
 -2.63096847e-01  8.85726668e-02  6.82564996e-02  8.29327642e-02
  2.78423186e-01 -9.03766817e-03 -2.35129632e-02 -4.77456319e-01]
Model bias: 0.336391489088412
Loss on 4 fold
Train loss = 1133.1394056089534
Test loss = 1198.5218906549942

Model coefficients: [ 4.22612624e-01 -1.16648536e+00 -3.44567286e-01 -2.13882443e-01
  2.45473657e-01  8.02940894e-02  6.10197240e-01  6.59511787e-01
  3.39252053e-01 -5.98739507e-01 -5.09210016e-01  7.58917744e-01
  2.04400549e+00  1.93920495e-01 -2.51747598e-01  1.73914101e-01
  1.14602042e+00  1.68593624e+00  6.80563005e-01  2.14156177e-01
 -4.17471477e-02  4.76269877e-01  5.70797490e-01  1.57318052e-01
  2.20043274e-01 -6.75435827e-01 -6.12919197e-01 -1.88743025e-01
  2.60349127e-01  1.52634616e+00  1.05239414e+01 -8.81500078e-01
  2.01439031e+00  9.19139469e+00 -5.30217153e+00 -9.58958706e-03
  3.35944220e+00  7.74523282e-01 -2.26268590e-01 -1.74024218e-01
 -6.52056317e-02  3.46715433e-01  2.50350941e-01  8.36754762e-02
 -2.53185074e-01 -3.21500922e-03  1.65921042e-01  1.78093225e-01
  1.88613208e-01  6.19502540e-02 -1.43641901e-01 -4.39124091e-01]
Model bias: 0.3452447735246438
Loss on 5 fold
Train loss = 1175.0658579916822
Test loss = 1044.1995917907066

Learning rate = 0.0001
Batch size = 5000
Train RMSE on folds 1-5 
32.07812505958153 | 34.77670618924219 | 33.833308224863835 | 33.662136082087144 | 34.2792336260845 | 
Test RMSE on folds 1-5 
40.96523272021893 | 29.416565565482394 | 34.03503349265789 | 34.61967490683577 | 32.31407730062405 | 
Train R2 on folds 1-5 
0.3848253619466501 | 0.43395239909669736 | 0.41658040391632045 | 0.4411978429867132 | 0.43068541220075507 | 
Test R2 on folds 1-5 
0.5297588174789701 | 0.6073616761675983 | 0.35143175519482833 | 0.3404309520872713 | 0.43230344583340086 | 
Train RMSE Mean = 33.72590183637185
Test RMSE Mean = 34.2701167971638
Train R2 Mean = 0.4214482840294272
Test R2 Mean = 0.4522573293524138
Train RMSE STD = 0.9100699277918965
Test RMSE STD = 3.8048674701182628
Train R2 STD = 0.019983278950928593
Test R2 STD = 0.10308533512264376

-------------------------------------
